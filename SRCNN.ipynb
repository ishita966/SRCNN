{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GZvmLkZ80u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import pprint\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import random\n",
        "from PIL import Image  # for loading images as YCbCr format\n",
        "import scipy.misc\n",
        "import scipy.ndimage\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXIZo9lO888R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch=5\n",
        "batch_size=4\n",
        "image_size=33\n",
        "label_size=21\n",
        "learning_rate=0.9\n",
        "c_dim=1\n",
        "scale=3\n",
        "stride=14\n",
        "#checkpoint_dir=checkpoint\n",
        "#sample_dir=sample\n",
        "is_train=True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aKUh6lld_lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMKoZEGU-xPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "pp = pprint.PrettyPrinter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itpvVkxR9N7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  xrange\n",
        "except:\n",
        "  xrange = range"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNXh1wcZ9bLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SRCNN(object):\n",
        "\n",
        "  def __init__(self, \n",
        "               sess, \n",
        "               image_size=33,\n",
        "               label_size=21, \n",
        "               batch_size=128,\n",
        "               c_dim=1, \n",
        "               checkpoint_dir=None, \n",
        "               sample_dir=None):\n",
        "\n",
        "    self.sess = sess\n",
        "    self.is_grayscale = (c_dim == 1)\n",
        "    self.image_size = image_size\n",
        "    self.label_size = label_size\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.c_dim = c_dim\n",
        "\n",
        "    self.checkpoint_dir = checkpoint_dir\n",
        "    self.sample_dir = sample_dir\n",
        "    self.build_model()\n",
        "\n",
        "  def build_model(self):\n",
        "    self.images = tf.placeholder(tf.float32, [None, self.image_size, self.image_size, self.c_dim], name='images')\n",
        "    self.labels = tf.placeholder(tf.float32, [None, self.label_size, self.label_size, self.c_dim], name='labels')\n",
        "    \n",
        "    self.weights = {\n",
        "      'w1': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name='w1'),\n",
        "      'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
        "      'w3': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name='w3')\n",
        "    }\n",
        "    self.biases = {\n",
        "      'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
        "      'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
        "      'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
        "    }\n",
        "\n",
        "    self.pred = self.model()\n",
        "\n",
        "    # Loss function (MSE)\n",
        "    self.loss = tf.reduce_mean(tf.square(self.labels - self.pred))\n",
        "\n",
        "    self.saver = tf.train.Saver()\n",
        "\n",
        "  def train(self, config):\n",
        "    if config.is_train:\n",
        "      input_setup(self.sess, config)\n",
        "    else:\n",
        "      nx, ny = input_setup(self.sess, config)\n",
        "\n",
        "    if config.is_train:     \n",
        "      data_dir = os.path.join('./{}'.format(config.checkpoint_dir), \"train.h5\")\n",
        "    else:\n",
        "      data_dir = os.path.join('./{}'.format(config.checkpoint_dir), \"test.h5\")\n",
        "\n",
        "    train_data, train_label = read_data(data_dir)\n",
        "\n",
        "    # Stochastic gradient descent with the standard backpropagation\n",
        "    self.train_op = tf.train.GradientDescentOptimizer(config.learning_rate).minimize(self.loss)\n",
        "\n",
        "    tf.initialize_all_variables().run()\n",
        "    \n",
        "    counter = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    if self.load(self.checkpoint_dir):\n",
        "      print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "      print(\" [!] Load failed...\")\n",
        "\n",
        "    if config.is_train:\n",
        "      print(\"Training...\")\n",
        "\n",
        "      for ep in xrange(config.epoch):\n",
        "        # Run by batch images\n",
        "        batch_idxs = len(train_data) // config.batch_size\n",
        "        for idx in xrange(0, batch_idxs):\n",
        "          batch_images = train_data[idx*config.batch_size : (idx+1)*config.batch_size]\n",
        "          batch_labels = train_label[idx*config.batch_size : (idx+1)*config.batch_size]\n",
        "\n",
        "          counter += 1\n",
        "          _, err = self.sess.run([self.train_op, self.loss], feed_dict={self.images: batch_images, self.labels: batch_labels})\n",
        "\n",
        "          if counter % 10 == 0:\n",
        "            print(\"Epoch: [%2d], step: [%2d], time: [%4.4f], loss: [%.8f]\" \\\n",
        "              % ((ep+1), counter, time.time()-start_time, err))\n",
        "\n",
        "          if counter % 500 == 0:\n",
        "            self.save(config.checkpoint_dir, counter)\n",
        "\n",
        "    else:\n",
        "      print(\"Testing...\")\n",
        "\n",
        "      result = self.pred.eval({self.images: train_data, self.labels: train_label})\n",
        "\n",
        "      result = merge(result, [nx, ny])\n",
        "      result = result.squeeze()\n",
        "      image_path = os.path.join(os.getcwd(), config.sample_dir)\n",
        "      image_path = os.path.join(image_path, \"test_image.png\")\n",
        "      imsave(result, image_path)\n",
        "\n",
        "  def model(self):\n",
        "    conv1 = tf.nn.relu(tf.nn.conv2d(self.images, self.weights['w1'], strides=[1,1,1,1], padding='VALID') + self.biases['b1'])\n",
        "    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, self.weights['w2'], strides=[1,1,1,1], padding='VALID') + self.biases['b2'])\n",
        "    conv3 = tf.nn.conv2d(conv2, self.weights['w3'], strides=[1,1,1,1], padding='VALID') + self.biases['b3']\n",
        "    return conv3\n",
        "\n",
        "  def save(self, checkpoint_dir, step):\n",
        "    model_name = \"SRCNN.model\"\n",
        "    model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    self.saver.save(self.sess,\n",
        "                    os.path.join(checkpoint_dir, model_name),\n",
        "                    global_step=step)\n",
        "\n",
        "  def load(self, checkpoint_dir):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "    model_dir = \"%s_%s\" % (\"srcnn\", self.label_size)\n",
        "    checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqn13NAk9iWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "  \"\"\"\n",
        "  Read h5 format data file\n",
        "  \n",
        "  Args:\n",
        "    path: file path of desired file\n",
        "    data: '.h5' file format that contains train data values\n",
        "    label: '.h5' file format that contains train label values\n",
        "  \"\"\"\n",
        "  with h5py.File(path, 'r') as hf:\n",
        "    data = np.array(hf.get('data'))\n",
        "    label = np.array(hf.get('label'))\n",
        "    return data, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1QMqF8S9xZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(path, scale=3):\n",
        "  \"\"\"\n",
        "  Preprocess single image file \n",
        "    (1) Read original image as YCbCr format (and grayscale as default)\n",
        "    (2) Normalize\n",
        "    (3) Apply image file with bicubic interpolation\n",
        "  Args:\n",
        "    path: file path of desired file\n",
        "    input_: image applied bicubic interpolation (low-resolution)\n",
        "    label_: image with original resolution (high-resolution)\n",
        "  \"\"\"\n",
        "  image = imread(path, is_grayscale=True)\n",
        "  label_ = modcrop(image, scale)\n",
        "\n",
        "  # Must be normalized\n",
        "  image = image / 255.\n",
        "  label_ = label_ / 255.\n",
        "\n",
        "  input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
        "  input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
        "\n",
        "  return input_, label_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYyeM0xe90BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(sess, dataset):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    dataset: choose train dataset or test dataset\n",
        "    \n",
        "    For train dataset, output data would be ['.../t1.bmp', '.../t2.bmp', ..., '.../t99.bmp']\n",
        "  \"\"\"\n",
        "  if FLAGS.is_train:\n",
        "    filenames = os.listdir(dataset)\n",
        "    data_dir = os.path.join(os.getcwd(), dataset)\n",
        "    data = glob.glob(os.path.join(data_dir, \"*.bmp\"))\n",
        "  else:\n",
        "    data_dir = os.path.join(os.sep, (os.path.join(os.getcwd(), dataset)), \"Set5\")\n",
        "    data = glob.glob(os.path.join(data_dir, \"*.bmp\"))\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLFr2mTG93I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_data(sess, data, label):\n",
        "  \"\"\"\n",
        "  Make input data as h5 file format\n",
        "  Depending on 'is_train' (flag value), savepath would be changed.\n",
        "  \"\"\"\n",
        "  if FLAGS.is_train:\n",
        "    savepath = os.path.join(os.getcwd(), 'checkpoint/train.h5')\n",
        "  else:\n",
        "    savepath = os.path.join(os.getcwd(), 'checkpoint/test.h5')\n",
        "\n",
        "  with h5py.File(savepath, 'w') as hf:\n",
        "    hf.create_dataset('data', data=data)\n",
        "    hf.create_dataset('label', data=label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWsTNhs98Wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imread(path, is_grayscale=True):\n",
        "  \"\"\"\n",
        "  Read image using its path.\n",
        "  Default value is gray-scale, and image is read by YCbCr format as the paper said.\n",
        "  \"\"\"\n",
        "  if is_grayscale:\n",
        "    return scipy.misc.imread(path, flatten=True, mode='YCbCr').astype(np.float)\n",
        "  else:\n",
        "    return scipy.misc.imread(path, mode='YCbCr').astype(np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOG4bzUn9_2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modcrop(image, scale=3):\n",
        "  \"\"\"\n",
        "  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
        "  \n",
        "  We need to find modulo of height (and width) and scale factor.\n",
        "  Then, subtract the modulo from height (and width) of original image size.\n",
        "  There would be no remainder even after scaling operation.\n",
        "  \"\"\"\n",
        "  if len(image.shape) == 3:\n",
        "    h, w, _ = image.shape\n",
        "    h = h - np.mod(h, scale)\n",
        "    w = w - np.mod(w, scale)\n",
        "    image = image[0:h, 0:w, :]\n",
        "  else:\n",
        "    h, w = image.shape\n",
        "    h = h - np.mod(h, scale)\n",
        "    w = w - np.mod(w, scale)\n",
        "    image = image[0:h, 0:w]\n",
        "  return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYKi7E_8-Cr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_setup(sess, config):\n",
        "  \"\"\"\n",
        "  Read image files and make their sub-images and saved them as a h5 file format.\n",
        "  \"\"\"\n",
        "  # Load data path\n",
        "  if config.is_train:\n",
        "    data = prepare_data(sess, dataset=\"Train\")\n",
        "  else:\n",
        "    data = prepare_data(sess, dataset=\"Test\")\n",
        "\n",
        "  sub_input_sequence = []\n",
        "  sub_label_sequence = []\n",
        "  padding = abs(config.image_size - config.label_size) / 2 # 6\n",
        "\n",
        "  if config.is_train:\n",
        "    for i in xrange(len(data)):\n",
        "      input_, label_ = preprocess(data[i], config.scale)\n",
        "\n",
        "      if len(input_.shape) == 3:\n",
        "        h, w, _ = input_.shape\n",
        "      else:\n",
        "        h, w = input_.shape\n",
        "\n",
        "      for x in range(0, h-config.image_size+1, config.stride):\n",
        "        for y in range(0, w-config.image_size+1, config.stride):\n",
        "          sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
        "          sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n",
        "\n",
        "          # Make channel value\n",
        "          sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
        "          sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
        "\n",
        "          sub_input_sequence.append(sub_input)\n",
        "          sub_label_sequence.append(sub_label)\n",
        "\n",
        "  else:\n",
        "    input_, label_ = preprocess(data[2], config.scale)\n",
        "\n",
        "    if len(input_.shape) == 3:\n",
        "      h, w, _ = input_.shape\n",
        "    else:\n",
        "      h, w = input_.shape\n",
        "\n",
        "    # Numbers of sub-images in height and width of image are needed to compute merge operation.\n",
        "    nx = ny = 0 \n",
        "    for x in range(0, h-config.image_size+1, config.stride):\n",
        "      nx += 1; ny = 0\n",
        "      for y in range(0, w-config.image_size+1, config.stride):\n",
        "        ny += 1\n",
        "        sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]\n",
        "        sub_label = label_[x+int(padding):x+int(padding)+config.label_size, y+int(padding):y+int(padding)+config.label_size] # [21 x 21]\n",
        "        \n",
        "        sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  \n",
        "        sub_label = sub_label.reshape([config.label_size, config.label_size, 1])\n",
        "\n",
        "        sub_input_sequence.append(sub_input)\n",
        "        sub_label_sequence.append(sub_label)\n",
        "\n",
        "  \"\"\"\n",
        "  len(sub_input_sequence) : the number of sub_input (33 x 33 x ch) in one image\n",
        "  (sub_input_sequence[0]).shape : (33, 33, 1)\n",
        "  \"\"\"\n",
        "  # Make list to numpy array. With this transform\n",
        "  arrdata = np.asarray(sub_input_sequence) # [?, 33, 33, 1]\n",
        "  arrlabel = np.asarray(sub_label_sequence) # [?, 21, 21, 1]\n",
        "\n",
        "  make_data(sess, arrdata, arrlabel)\n",
        "\n",
        "  if not config.is_train:\n",
        "    return nx, ny\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4NPp7Ii-Ijr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imsave(image, path):\n",
        "  return scipy.misc.imsave(path, image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPKVD3D3-KrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge(images, size):\n",
        "  h, w = images.shape[1], images.shape[2]\n",
        "  img = np.zeros((h*size[0], w*size[1], 1))\n",
        "  for idx, image in enumerate(images):\n",
        "    i = idx % size[1]\n",
        "    j = idx // size[1]\n",
        "    img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
        "\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCr0gseE-M3L",
        "colab_type": "code",
        "outputId": "e94ad8ad-98e7-49b3-8a2b-781a7061b473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "def main():\n",
        "  \n",
        "\n",
        " # if not os.path.exists(checkpoint_dir):\n",
        "  #  os.makedirs(checkpoint_dir)\n",
        "  #if not os.path.exists(sample_dir):\n",
        "   # os.makedirs(sample_dir)\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    srcnn = SRCNN(sess, \n",
        "                  image_size=image_size, \n",
        "                  label_size=label_size, \n",
        "                  batch_size=batch_size,\n",
        "                  c_dim=c_dim)\n",
        "\n",
        "    srcnn.train()\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4ea49f8c26cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FTh_10Z-pIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}